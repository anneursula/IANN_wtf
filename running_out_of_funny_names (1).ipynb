{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "running_out_of_funny_names.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "krqfpFM_FCO-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "from collections import Counter \n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpwceQUqFEBy"
      },
      "source": [
        "datatf = tfds.load('tiny_shakespeare')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tul32-xKFRY9"
      },
      "source": [
        "shakes_train, shakes_test = datatf['train'], datatf['test']\n",
        "shakes_train = shakes_train.map(lambda t: t['text'])\n",
        "# shakes_train = shakes_train.map(lambda t: t.numpy())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JFmpDIv9BKgK",
        "outputId": "1f862b58-102f-46b2-ef6c-e1f3b8f2361e"
      },
      "source": [
        "i = 1\n",
        "string= '123456'\n",
        "s = string[:-i]\n",
        "s"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'12345'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGrzI9e-Fszi"
      },
      "source": [
        "id_counter = 1\n",
        "dict_codes = {}\n",
        "dict_words = {}\n",
        "dict_counts = {}\n",
        "word_counts = 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XORcxvWqGe67",
        "outputId": "f1f37b33-b3f1-4d63-fee9-beab3efd9bf6"
      },
      "source": [
        "data =[]\n",
        "bunches = []\n",
        "coded_data = None\n",
        "\n",
        "window_length = 20\n",
        "for c, i in enumerate(shakes_train):\n",
        "  \n",
        "  text = i.numpy()\n",
        "  text = str(text).strip('b\"')\n",
        "  text = text.lower()\n",
        "\n",
        "  text = text.replace(\"\\\\n\", \" \")\n",
        "  text = text.replace(\"  \", \" \")\n",
        "\n",
        "  data = [char for char in text]\n",
        "  chars = set(data)\n",
        "  dict_codes = {}\n",
        "  dict_chars = {}\n",
        "  for i, char in enumerate(chars):\n",
        "    dict_codes[char] = i\n",
        "    dict_chars[i] = char\n",
        "\n",
        "  coded_data = [[float(dict_codes[char])] for char in data]\n",
        "\n",
        " \n",
        "print(coded_data[:20])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[20.0], [11.0], [9.0], [25.0], [17.0], [35.0], [5.0], [11.0], [17.0], [11.0], [23.0], [13.0], [34.0], [18.0], [35.0], [7.0], [13.0], [20.0], [2.0], [9.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng_9Rp6jJq7B"
      },
      "source": [
        "input = np.array([coded_data[ i : i + 20] for i in range(len(coded_data) - 21)])\n",
        "target = np.array([coded_data[i + 1: i + 21] for i in range(len(coded_data) - 21)])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KoAvKYYuGhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0def075e-5ac1-4f4f-fa52-82128f9e5243"
      },
      "source": [
        "input.shape, target.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((997536, 20, 1), (997536, 20, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP4-ffRFrd8I"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(input)\r\n",
        "labels = tf.data.Dataset.from_tensor_slices(target)\r\n",
        "\r\n",
        "datas = dataset.batch(64)\r\n",
        "targets = labels.batch(64)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBXIsZoq0ish"
      },
      "source": [
        "ds = tf.data.Dataset.zip((dataset, labels)).batch(64)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ0I2F7fuPHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "672a2cc5-a869-49e9-d2e4-fb17f7e1c2d2"
      },
      "source": [
        "datas"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (None, 20, 1), types: tf.float64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKXL3xOZ2PMz"
      },
      "source": [
        "# We use a dynamic learning rate which decays exponantially\n",
        "# As an optimiser we use adam\n",
        "\n",
        "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.001, \n",
        "                                                    5000, \n",
        "                                                    0.96,\n",
        "                                                    staircase=True)\n",
        "opt = tf.optimizers.Adam(lr)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbzappDbBBrw"
      },
      "source": [
        "def most_similar(code, emb):\n",
        "  csf = keras.losses.CosineSimilarity()\n",
        "  emb_word = emb[code]\n",
        "  cos_sim = [csf(emb_word, emb[i]) if code != i else 1 for i in range(10000)]\n",
        "  min_val = min(cos_sim)\n",
        "  min_index = cos_sim.index(min_val)\n",
        "  return dict_words_new[min_index]\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC1zhMbw3VHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ee3aec-afab-4717-e5bc-efdbdbd2f4ef"
      },
      "source": [
        "test_sent = \"I sincerely like pla\"\r\n",
        "for c, i in enumerate(test_sent):\r\n",
        "  \r\n",
        "  data = [char for char in test_sent]\r\n",
        "  chars = set(data)\r\n",
        "  dict_codes = {}\r\n",
        "  dict_chars = {}\r\n",
        "  for i, char in enumerate(chars):\r\n",
        "    dict_codes[char] = i\r\n",
        "    dict_chars[i] = char\r\n",
        "\r\n",
        "  coded_data = [[float(dict_codes[char])] for char in data]\r\n",
        " \r\n",
        "print(coded_data[:20])\r\n",
        "\r\n",
        "test = tf.reshape(tf.convert_to_tensor(coded_data), (1,20,1))\r\n",
        "test"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8.0], [5.0], [7.0], [9.0], [3.0], [2.0], [11.0], [10.0], [11.0], [0.0], [12.0], [5.0], [0.0], [9.0], [4.0], [11.0], [5.0], [6.0], [0.0], [1.0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 20, 1), dtype=float32, numpy=\n",
              "array([[[ 8.],\n",
              "        [ 5.],\n",
              "        [ 7.],\n",
              "        [ 9.],\n",
              "        [ 3.],\n",
              "        [ 2.],\n",
              "        [11.],\n",
              "        [10.],\n",
              "        [11.],\n",
              "        [ 0.],\n",
              "        [12.],\n",
              "        [ 5.],\n",
              "        [ 0.],\n",
              "        [ 9.],\n",
              "        [ 4.],\n",
              "        [11.],\n",
              "        [ 5.],\n",
              "        [ 6.],\n",
              "        [ 0.],\n",
              "        [ 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypNN4cguDb2S"
      },
      "source": [
        "def testing(model):\r\n",
        "  pred = model(test).numpy()\r\n",
        "  sentence = [dict_chars[int(i)] for i in pred[0][1]]\r\n",
        "\r\n",
        "  return sentence"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmG1wcAdpvSJ"
      },
      "source": [
        "class LSTM(tf.keras.Model):\r\n",
        "    \r\n",
        "    def __init__(self, return_sequences=True):\r\n",
        "        \r\n",
        "        super(LSTM, self).__init__()\r\n",
        "        self.rnn = tf.keras.layers.LSTM(8, return_sequences=True)\r\n",
        "        # self.rnn = tf.keras.layers.RNN([tf.keras.layers.LSTMCell(8, return_sequences=True) for _ in range(5)], return_sequences)\r\n",
        "        self.output_layer = tf.keras.layers.Dense(units=1, activation='sigmoid')\r\n",
        "        \r\n",
        "    \r\n",
        "    def call(self, x):\r\n",
        "        \r\n",
        "        x = self.rnn(x)\r\n",
        "        x = self.output_layer(x)\r\n",
        "        return x"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_pt8FZDp3x4"
      },
      "source": [
        "def train(model, input, target, loss_f, optimizer): \r\n",
        "  with tf.GradientTape() as tape: \r\n",
        "    prediction = model(input)\r\n",
        "    loss = loss_f(target, prediction)\r\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "  acc = np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\r\n",
        "\r\n",
        "\r\n",
        "  return np.mean(loss.numpy()), np.mean(acc)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5rxg5hg0J6F"
      },
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "num_epochs = 10\r\n",
        "learning_rate = lr\r\n",
        "running_average_factor = 0.95\r\n",
        "\r\n",
        "\r\n",
        "cross_entropy_loss = tf.keras.losses.categorical_crossentropy\r\n",
        "\r\n",
        "optimizer = opt"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "NsEPopRjeNrZ",
        "outputId": "9c85e2e0-f290-4cf4-84b9-3a4e99d05baa"
      },
      "source": [
        "model = LSTM(return_sequences=True)\n",
        "\n",
        "# Custom training loop\n",
        "# Each epoch the model will learn on the shuffled and batched training data and will then evaluate the training step on the whole test dataset\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print('Epoch:__' + str(epoch))\n",
        "\n",
        "  # tr_ds = ds.shuffle(buffer_size=128).prefetch(2)\n",
        "  # te_ds = te_ds.shuffle(buffer_size=128).prefetch(2)\n",
        "  train_losses = []\n",
        "  train_accuracies = [] \n",
        "\n",
        "  running_average = 0\n",
        "  batch_acc = []\n",
        "  for (input, target) in tqdm(ds):\n",
        "\n",
        "    train_l, train_acc = train(model, input, target, cross_entropy_loss, optimizer)\n",
        "    running_average = (running_average_factor * running_average) + (1 - running_average_factor) * train_l\n",
        "    batch_acc.append(train_acc)\n",
        "\n",
        "  pred = testing(model)\n",
        "  print(pred)\n",
        "  train_losses.append(running_average)\n",
        "  train_accuracies.append(np.mean(batch_acc))\n",
        "  print('Train Accuracy: ', train_accuracies[-1])\n",
        "\n",
        "  # for word in track_codes:\n",
        "  #   sim_word = most_similar(word, model.layer_1.get_weights()[0])\n",
        "  #   print( dict_words_new[word], ': ', sim_word)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15587 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:__0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15587/15587 [03:01<00:00, 86.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-b9d9cc40ecfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mbatch_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-593f4878c1f5>\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict_chars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-593f4878c1f5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict_chars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m     if (Tensor._USE_EQUALITY and executing_eagerly_outside_functions() and\n\u001b[1;32m    829\u001b[0m         (g is None or g.building_function)):\n\u001b[0;32m--> 830\u001b[0;31m       raise TypeError(\"Tensor is unhashable. \"\n\u001b[0m\u001b[1;32m    831\u001b[0m                       \"Instead, use tensor.ref() as the key.\")\n\u001b[1;32m    832\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Tensor is unhashable. Instead, use tensor.ref() as the key."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DgF9o4qeTr8"
      },
      "source": [
        "# Visualize accuracy and loss for training and test data. \n",
        "# One plot training and test loss.\n",
        "# One plot training and test accuracy.\n",
        "plt.figure()\n",
        "line1, = plt.plot(train_losses)\n",
        "line2, = plt.plot(test_losses)\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend((line1,line2),(\"training\",\"test\"))\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "line1, = plt.plot(train_accuracies)\n",
        "line2, = plt.plot(test_accuracies)\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgJR3rdOg8lZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
