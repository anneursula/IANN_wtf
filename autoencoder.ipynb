{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eguFuqYagS47"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten \n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras import Sequential\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Reshape, Input\n",
        "from keras.layers import Conv2DTranspose\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmG7Xpb3gUrD"
      },
      "source": [
        "# Load cifar10 dataset\n",
        "(x_train, _), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FJssn0AgXM5"
      },
      "source": [
        "# Create dataset object from tensors and perform preprocessing\n",
        "# Preprocessing steps involved are:\n",
        "## cast tensors to float\n",
        "## normalize images to values between 0 and 1\n",
        "## one-hot encode labels\n",
        "## zip input and labels\n",
        "## batch dataset\n",
        "## shuffle dataset\n",
        " \n",
        "train_im = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "\n",
        "train_im = train_im.map(lambda img : tf.cast(img, tf.float32))\n",
        "train_im = train_im.map(lambda img : img/255)\n",
        "train_im = train_im.map(lambda img: tf.reshape(img, (28,28,1)))\n",
        "\n",
        "tr_ds = train_im.batch(64)\n",
        "\n",
        "\n",
        "#same for test set\n",
        "\n",
        "test_im = tf.data.Dataset.from_tensor_slices(x_test)\n",
        "\n",
        "test_im = test_im.map(lambda img : tf.cast(img, tf.float32))\n",
        "test_im = test_im.map(lambda img : img/255)\n",
        "test_im = train_im.map(lambda img: tf.reshape(img, (28,28,1)))\n",
        "\n",
        "\n",
        "te_ds = test_im.batch(64)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "A1jMzHTmgGk8",
        "outputId": "974c6c58-1d54-4659-b008-e66819028e30"
      },
      "source": [
        "for i in tr_ds:\n",
        "  plt.imshow(i[1,:,:,0])\n",
        "  break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8DpqmXegc0L"
      },
      "source": [
        "from keras import Model\n",
        "\n",
        "class Encoder(Model): \n",
        "  def __init__(self): \n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "\n",
        "    self.layers_list = [Conv2D(16, 3, padding='same', activation='relu'),\n",
        "                        BatchNormalization(), \n",
        "                        MaxPooling2D(2),\n",
        "\n",
        "                        Conv2D(32, 3, activation='relu', padding='same'),\n",
        "                        BatchNormalization(), \n",
        "\n",
        "                        MaxPooling2D(2),\n",
        "                        Conv2D(32, 3, activation='relu', padding='same'),\n",
        "                        BatchNormalization(),\n",
        "                        MaxPooling2D(2), \n",
        "\n",
        "                        Flatten(), \n",
        "                        Dense(10, activation='softmax')\n",
        "                        ]\n",
        "\n",
        "\n",
        "  def call(self, x):\n",
        "    for i, layer in enumerate(self.layers_list):\n",
        "      # print(tf.shape(x), '___',i)\n",
        "      x = layer(x)\n",
        "    # print(tf.shape(x), '___')\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(Model): \n",
        "  def __init__(self): \n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.layers_list = [Dense(49), \n",
        "                        Reshape((7,7,1)),\n",
        "                        Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "                        BatchNormalization(),\n",
        "                        UpSampling2D((2,2)), \n",
        "\n",
        "                        Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "                        BatchNormalization(),\n",
        "                        UpSampling2D((2,2)), \n",
        "\n",
        "                        Conv2D(32 ,(3,3), activation='relu', padding='same'),\n",
        "                        Conv2D(1, (3,3), activation='sigmoid', padding='same')\n",
        "                        ]\n",
        "\n",
        "\n",
        "  def call(self, x):\n",
        "    for i, layer in enumerate(self.layers_list):\n",
        "      # print(tf.shape(x), '___',i)\n",
        "      x = layer(x)\n",
        "    # print(tf.shape(x), '___',i)\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67iGNRGTeVej"
      },
      "source": [
        "class AutoEncoder(Model):\n",
        "  def __init__(self):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "\n",
        "    self.layers_list= [Encoder(),\n",
        "                       Decoder()]\n",
        "\n",
        "  def call(self, x):\n",
        "    for layer in self.layers_list:\n",
        "      x = layer(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def get_enc(self):\n",
        "    return self.layers_list[0]\n",
        "\n",
        "\n",
        "  def get_dec(self):\n",
        "    return self.layers_list[1]\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "xM-ZXsigaeK6",
        "outputId": "b9be146f-0930-4e4f-a5bd-7179b4bac169"
      },
      "source": [
        "enc = Encoder()\n",
        "\n",
        "dec = Decoder()\n",
        "inp = tf.random.normal((28,28,1))\n",
        "inp = tf.reshape(inp, (1,28,28,1))\n",
        "#out = tf.constant([-0.23541524, -0.0633513 , -0.14792025, -0.49539533,  0.7927028 , 0.04283119,  0.02038066,  0.12454496], shape=(8,1))\n",
        "\n",
        "res = dec(enc(inp))\n",
        "plt.imshow(res[0,:,:,0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdbcff91630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym4-whn4kISu"
      },
      "source": [
        "# We use a dynamic learning rate which decays exponantially\n",
        "# As an optimiser we use adam\n",
        "\n",
        "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.001, \n",
        "                                                    5000, \n",
        "                                                    0.97,\n",
        "                                                    staircase=True)\n",
        "opt = tf.optimizers.Adam(learning_rate=lr)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GjjVWVgj6QA"
      },
      "source": [
        "# model = DenseNet()\n",
        "\n",
        "# model.compile(optimizer=opt, \n",
        "#              loss='categorical_crossentropy', \n",
        "#              metrics=['acc'])\n",
        "\n",
        "# model.fit(tr_ds, validation_data=te_ds, epochs=30, shuffle=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRETQYXeKp9w"
      },
      "source": [
        "# Training method returns mean loss and mean accuracy of the batch\n",
        "\n",
        "def train(model, input, target, loss_f, optimizer): \n",
        "  with tf.GradientTape() as tape: \n",
        "    prediction = model(input)\n",
        "    loss = loss_f(target, prediction)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  acc = np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
        "\n",
        "\n",
        "  return np.mean(loss.numpy()), np.mean(acc)\n",
        "\n",
        "\n",
        "# Test method takes in whole test dataset and returns mean loss and mean accuracy on the whole test data\n",
        "def test(model, test_data, loss_f): \n",
        "  test_acc = []\n",
        "  test_loss = []\n",
        "  #pred = None\n",
        "\n",
        "  fig, axes = plt.subplots(10,2, figsize=(50,10))\n",
        "\n",
        "  for i, input in enumerate(test_data): \n",
        "    prediction = model(input, training=False)\n",
        "    loss = loss_f(input, prediction)\n",
        "    loss = np.mean(loss.numpy())\n",
        "    acc = np.argmax(input, axis=1) == np.argmax(prediction, axis=1)\n",
        "    test_loss.append(loss)\n",
        "    test_acc.append(np.mean(acc))\n",
        "    if i < 10:\n",
        "      axes[i,0].imshow(input[0,:,:,0], )\n",
        "      axes[i,1].imshow(prediction[0,:,:,0])\n",
        "  \n",
        "  \n",
        "\n",
        "  fin_loss = np.mean(np.array(test_loss))\n",
        "  fin_acc = np.mean(test_acc)\n",
        "\n",
        "  return fin_loss, fin_acc, axes"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CWWk9f0zwTM"
      },
      "source": [
        "# Define additional hyperparameters\n",
        "\n",
        "# Loss is categorical crossentropy\n",
        "# The model will train for 30 epochs\n",
        "\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "running_average_factor = 0.95\n",
        "\n",
        "\n",
        "loss = tf.keras.losses.MSE\n",
        "\n",
        "optimizer = opt\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvJ3PLSUzxYy",
        "outputId": "68412cd1-fa43-4570-d309-1d9a8905b5c4"
      },
      "source": [
        "# Custom training loop\n",
        "# Each epoch the model will learn on the shuffled and batched training data and will then evaluate the training step on the whole test dataset\n",
        "\n",
        "model = AutoEncoder()\n",
        "for epoch in range(num_epochs):\n",
        "  print('Epoch:__' + str(epoch))\n",
        "\n",
        "  tr_ds = tr_ds.shuffle(buffer_size=128).prefetch(2)\n",
        "  te_ds = te_ds.shuffle(buffer_size=128).prefetch(2)\n",
        "\n",
        "\n",
        "  running_average = 0\n",
        "  batch_acc = []\n",
        "  for input in tr_ds: \n",
        "    train_l, train_acc = train(model, input, input, loss, optimizer)\n",
        "    running_average = (running_average_factor * running_average) + (1 - running_average_factor) * train_l\n",
        "    batch_acc.append(train_acc)\n",
        "\n",
        "  train_losses.append(running_average)\n",
        "  train_accuracies.append(np.mean(batch_acc))\n",
        "  print('Train losses: ', train_losses[-1])\n",
        "\n",
        "  #testing\n",
        "  test_loss, test_accu, axes = test(model, te_ds, loss)\n",
        "  test_losses.append(test_loss)\n",
        "  test_accuracies.append(test_accu)\n",
        "  #axes.draw()\n",
        "  print('Test loss: ', test_loss)\n",
        "  print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:__0\n",
            "Train losses:  0.026924545333338237\n",
            "Test loss:  0.027394159\n",
            "\n",
            "Epoch:__1\n",
            "Train losses:  0.02376269679719912\n",
            "Test loss:  0.023766547\n",
            "\n",
            "Epoch:__2\n",
            "Train losses:  0.021958484768357\n",
            "Test loss:  0.021619828\n",
            "\n",
            "Epoch:__3\n",
            "Train losses:  0.020581574005801007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xenhOwxnz3GT"
      },
      "source": [
        "# Visualize accuracy and loss for training and test data. \n",
        "# One plot training and test loss.\n",
        "# One plot training and test accuracy.\n",
        "plt.figure()\n",
        "line1, = plt.plot(train_losses)\n",
        "line2, = plt.plot(test_losses)\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend((line1,line2),(\"training\",\"test\"))\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "line1, = plt.plot(train_accuracies)\n",
        "line2, = plt.plot(test_accuracies)\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIBwwo9oD20e"
      },
      "source": [
        "images = test_im.batch(1)\n",
        "enc = model.get_enc()\n",
        "encoded_images = []\n",
        "for i, im in enumerate(images):\n",
        "  encoded_images.append(enc(im))\n",
        "  if i > 998:\n",
        "    break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ1azfAbLihN"
      },
      "source": [
        "print(encoded_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB04WfC5MjOy"
      },
      "source": [
        "encoded_ima = np.asarray(encoded_images)\n",
        "encoded_ima = encoded_ima.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArHzwkMqMnUE"
      },
      "source": [
        "tee_schnirt = []\n",
        "tsne = TSNE()\n",
        "tee_schnirt.append(tsne.fit_transform(encoded_ima))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhGII5W3TSs5"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWjijn2cONOm"
      },
      "source": [
        "tee = np.asarray(tee_schnirt).squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC9Mj-2_ORMF"
      },
      "source": [
        "group = np.array([1,2,3,4,5,6,7,8,9,0])\n",
        "cdict = {1: 'red', 2: 'blue', 3: 'green', 4: 'purple', 5: 'black', 6: 'orange', 7: 'pink', 8: 'brown', 9: 'peru', 0: 'magenta'}\n",
        "#ndict = {1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle Boot', 0: 'T-Shirt/Top'}\n",
        "\n",
        "# print(cdict[y_test[1]])\n",
        "fig, ax = plt.subplots()\n",
        "for i, data in enumerate(tee):\n",
        "  # print(data)\n",
        "  ax.scatter(data[0], data[1], c = cdict[y_test[i]], s = 50)\n",
        "# ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NywsA_rRR498"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}